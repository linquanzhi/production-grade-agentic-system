# 项目架构与工作流程分析报告

## 1. 总体架构设计

本项目采用分层架构设计，结合了现代智能体（Agentic）系统的核心模式，具有高可靠性、可观测性和可扩展性。

### 核心分层：
- **API 接口层 (`src/interface/`)**: 基于 FastAPI 构建，负责处理 HTTP 请求、身份验证（JWT）和 API 路由分发。
- **智能体编排层 (`src/agent/`)**: 使用 LangGraph 构建的有状态工作流，定义了智能体的决策逻辑、工具调用循环和状态转换。
- **业务服务层 (`src/services/`)**: 
    - **LLM 提供商**: 实现自动重试、指数退避和跨模型循环回退（如从 GPT-4 降级到 GPT-3.5）。
    - **数据库管理**: 负责 PostgreSQL 连接池管理及 CRUD 操作。
- **数据持久化层 (`src/data/`)**: 
    - 使用 SQLModel 处理关系数据。
    - 使用 `pgvector` 处理向量数据。
    - 使用 PostgreSQL 存储 LangGraph 的对话状态（Checkpoints）。
- **系统基础设施层 (`src/system/`)**: 提供日志记录、Prometheus 指标监控、速率限制和遥测。

---

## 2. 核心组件交互

1.  **LangGraph**: 作为系统的“大脑”，协调 LLM 和外部工具。
2.  **Mem0**: 作为长期记忆系统，负责从对话中提取关键事实，并通过向量检索在后续对话中提供上下文。
3.  **Langfuse**: 提供生产级的追踪（Tracing），记录每一次 LLM 调用、工具执行和状态变更。
4.  **Prometheus & Grafana**: 监控系统的延迟、吞吐量和错误率等实时指标。

---

## 3. 请求工作流程

当一个聊天请求（Chat Request）进入系统时，其流转路径如下：

### 步骤 1：接入与验证
- **请求进入**: FastAPI 接收请求，通过中间件记录日志并更新 Prometheus 指标。
- **速率限制**: `SlowAPI` 根据 IP 或用户 ID 检查请求频率。
- **认证**: 验证 JWT 令牌，确认用户身份。

### 步骤 2：上下文加载
- **会话恢复**: LangGraph 根据 `thread_id` 从 PostgreSQL 加载之前的对话状态。
- **长期记忆检索**: `Mem0` 根据当前用户的历史和输入，从向量数据库中检索相关背景信息。
- **提示词组装**: 加载系统提示词，并将检索到的长期记忆和对话历史注入到提示词模板中。

### 步骤 3：智能体决策循环（LangGraph）
- **Chat 节点**: LLM 接收上下文并决定下一步动作（直接回复或调用工具）。
- **工具调用（可选）**: 
    - 如果需要搜索，智能体将流转至 `tool_call` 节点。
    - 调用 `DuckDuckGo` 等外部工具获取数据。
    - 将工具结果反馈回智能体，再次由 LLM 处理。

### 步骤 4：韧性处理（LLM 服务的弹性）
- **重试机制**: 如果 OpenAI API 超时或报错，`LLMService` 会执行指数退避重试。
- **模型回退**: 如果主模型持续失败，系统会自动切换到备用模型（例如从 `gpt-4o` 切换到 `gpt-4o-mini`）。

### 步骤 5：状态持久化与回复
- **保存状态**: 最终生成的对话状态被存回 PostgreSQL 检查点。
- **记忆提取**: 系统开启后台异步任务，使用 `Mem0` 从本次对话中提取新事实并存储到向量库。
- **返回响应**: 将结果返回给用户（支持 SSE 流式返回）。

---

## 4. 关键设计亮点
- **异步优先**: 系统广泛使用 `asyncio`，确保在处理 I/O 密集型任务（如 LLM 调用和数据库查询）时保持高性能。
- **可观察性驱动**: 每一个关键节点都埋有监控点，方便在生产环境中快速定位推理延迟或逻辑错误。
- **状态自愈**: 通过 LangGraph 的检查点机制，即使系统崩溃，对话也可以从最后一个稳定的节点恢复。
